# AI-SDev-Week7
## AI Ethics Assignment
####Description      Assignment: AI Ethics
Theme:Â "Designing Responsible and Fair AI Systems"Â ğŸŒâš–ï¸

### Objective & Guidelnes
This assignment evaluates the understanding ofÂ AI ethics principles, ability to identify and mitigate biases, and skill in applying ethical frameworks to real-world scenarios. You will analyze case studies, audit AI systems, and propose solutions to ethical dilemmas.

### Tools & Resources
Libraries:Â AI Fairness 360,Â Pandas,Â Matplotlib.
Datasets: COMPAS (provided),Â ProPublicaâ€™s Analysis. https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm
Frameworks:Â EU Ethics Guidelines for Trustworthy AI. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai

Why This Matters
Societal Impact: Ethical AI prevents harm and fosters trust in technology.
Career Skill: Employers prioritize ethical competency in AI roles.
Build AI thatâ€™s fair, transparent, and human-centric! ğŸŒŸ

Need Help?
UseÂ AI Fairness 360Â GitHub Repository.https://github.com/Trusted-AI/AIF360.git

Pro Tip: Start with fairness metrics likeÂ disparate impact ratioÂ andÂ equal opportunity difference. Small steps lead to big ethical wins!       
Part 1: Theoretical UnderstandingÂ 
1. Short Answer Questions
Q1: DefineÂ algorithmic biasÂ and provide two examples of how it manifests in AI systems.

Q2: Explain the difference betweenÂ transparencyÂ andÂ explainabilityÂ in AI. Why are both important?

Q3: How does GDPR (General Data Protection Regulation) impact AI development in the EU?
2. Ethical Principles Matching
Match the following principles to their definitions:
A) Justice
B) Non-maleficence
C) Autonomy
D) Sustainability
Ensuring AI does not harm individuals or society.
Respecting usersâ€™ right to control their data and decisions.
Designing AI to be environmentally friendly.
Fair distribution of AI benefits and risks.


Part 2: Case Study AnalysisÂ 
Case 1: Biased Hiring Tool
Scenario: Amazonâ€™s AI recruiting tool penalized female candidates.
Tasks:
Identify the source of bias (e.g., training data, model design).
Propose three fixes to make the tool fairer.
Suggest metrics to evaluate fairness post-correction.

Case 2: Facial Recognition in Policing
Scenario: A facial recognition system misidentifies minorities at higher rates.
Tasks:
Discuss ethical risks (e.g., wrongful arrests, privacy violations).
Recommend policies for responsible deployment.

Part 3: Practical AuditÂ 
Task: Audit a Dataset for Bias
Dataset:Â COMPAS Recidivism Dataset. https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis

Goal:
Use Python andÂ AI Fairness 360Â (IBMâ€™s toolkit) to analyze racial bias in risk scores.
Generate visualizations (e.g., disparity in false positive rates).
Write a 300-word report summarizing findings and remediation steps.
Deliverable: Code + report.

Part 4: Ethical ReflectionÂ 
Prompt: Reflect on a personal project (past or future). How will you ensure it adheres to ethical AI principles?
Bonus TaskÂ 
Policy Proposal: Draft a 1-page guideline forÂ ethical AI use in healthcare. Include:
Patient consent protocols.
Bias mitigation strategies.
Transparency requirements.           
